# Logits in Deep Learning

In deep learning, "logits" refers to the raw, unnormalized predictions generated by a model before applying an activation function. Logits are often the output of the final layer of a neural network before passing through a softmax function (in classification tasks) or a sigmoid function (in binary classification tasks).

## Meaning of Logits:

- **Definition:** Logits are real-valued scores or probabilities associated with each class in a classification task. They represent the evidence that a particular class is present in a given input.

- **Unnormalized Predictions:** Logits are unnormalized predictions, meaning they have not been transformed or normalized to represent probabilities.

- **Linear Output:** Logits are typically obtained by performing a linear transformation (e.g., matrix multiplication followed by addition of bias) on the final layer's output.

## Properties and Usage:

- **Range of Logits:** Logits can take any real value, positive or negative. They are not constrained to a specific range like probabilities.

- **Interpretation:** Higher logit values indicate stronger evidence for the presence of a particular class, while lower logit values indicate weaker evidence.

- **Activation Function:** Logits are often passed through an activation function to convert them into probabilities that can be interpreted as class probabilities.

## Example:

In a multi-class classification task, suppose we have a neural network that predicts the probabilities of three classes (e.g., "cat," "dog," "horse"). The logits produced by the final layer of the network might look like this:

